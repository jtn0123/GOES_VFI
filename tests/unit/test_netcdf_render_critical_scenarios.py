"""Critical scenario tests for NetCDF rendering functionality.

This test suite covers high-priority missing areas identified in the testing gap analysis:
1. Data accuracy validation and corruption handling
2. Memory management with extremely large files
3. Invalid file format and structure handling
4. Colormap application edge cases
5. Performance under stress conditions
6. Data masking and invalid value handling
7. Numerical precision in temperature conversions
"""

import gc
import os
from pathlib import Path
import tempfile
import time
from typing import Any
from unittest.mock import MagicMock, patch

import numpy as np
import pytest
import xarray as xr

from goesvfi.integrity_check.render.netcdf import (
    BAND_ID_VAR,
    DEFAULT_MAX_TEMP_K,
    DEFAULT_MIN_TEMP_K,
    RADIANCE_VAR,
    TARGET_BAND_ID,
    _convert_radiance_to_temperature,
    _get_colormap,
    _validate_band_id,
    extract_metadata,
    render_png,
)


class TestNetCDFRenderCritical:
    """Critical scenario tests for NetCDF rendering functions."""

    @pytest.fixture()
    def memory_test_generator(self) -> Any:
        """Generator for memory testing scenarios."""

        class MemoryTestGenerator:
            @staticmethod
            def create_large_dataset(width: int, height: int, realistic_radiance: bool = True) -> xr.Dataset:
                """Create large realistic dataset for memory testing."""
                # Limit size to prevent memory issues
                width = min(width, 500)
                height = min(height, 500)

                if realistic_radiance:
                    # Generate realistic GOES radiance values
                    # Typical range: 10-500 W m^-2 sr^-1 Î¼m^-1
                    rng = np.random.default_rng(42)
                    data = rng.gamma(2, 50, size=(height, width)).astype(np.float32)
                    # Add some realistic patterns
                    y_grid, _x_grid = np.meshgrid(np.arange(height), np.arange(width), indexing="ij")
                    temperature_gradient = 250 + 50 * np.sin(y_grid / height * np.pi)
                    # Convert temperature back to radiance approximately
                    data *= (temperature_gradient / 280.0) ** 4
                else:
                    data = np.random.random((height, width)).astype(np.float32) * 100

                return xr.Dataset(
                    {
                        RADIANCE_VAR: (["y", "x"], data),
                        BAND_ID_VAR: TARGET_BAND_ID,
                    },
                    coords={
                        "y": np.arange(height),
                        "x": np.arange(width),
                    },
                    attrs={
                        "platform_ID": "GOES-18",
                        "instrument_type": "ABI",
                        "planck_fk1": 202263.0,
                        "planck_fk2": 3698.0,
                        "planck_bc1": 0.5,
                        "planck_bc2": 0.9991,
                    },
                )

            @staticmethod
            def create_corrupted_dataset(corruption_type: str) -> xr.Dataset:
                """Create dataset with specific types of corruption."""
                base_data = np.random.random((100, 100)).astype(np.float32) * 100

                if corruption_type == "infinite_values":
                    base_data[10:20, 10:20] = np.inf
                    base_data[30:40, 30:40] = -np.inf
                elif corruption_type == "nan_blocks":
                    base_data[50:60, 50:60] = np.nan
                elif corruption_type == "extreme_values":
                    base_data[70:80, 70:80] = 1e10
                    base_data[80:90, 80:90] = -1e10
                elif corruption_type == "zero_division":
                    base_data[20:30, 20:30] = 0.0
                elif corruption_type == "mixed_corruption":
                    base_data[0:10, 0:10] = np.inf
                    base_data[10:20, 10:20] = np.nan
                    base_data[20:30, 20:30] = 0.0
                    base_data[30:40, 30:40] = 1e10

                return xr.Dataset(
                    {
                        RADIANCE_VAR: (["y", "x"], base_data),
                        BAND_ID_VAR: TARGET_BAND_ID,
                    },
                    coords={
                        "y": np.arange(100),
                        "x": np.arange(100),
                    },
                    attrs={
                        "platform_ID": "GOES-18",
                        "instrument_type": "ABI",
                        "planck_fk1": 202263.0,
                        "planck_fk2": 3698.0,
                        "planck_bc1": 0.5,
                        "planck_bc2": 0.9991,
                    },
                )

        return MemoryTestGenerator()

    def test_temperature_conversion_accuracy(self) -> None:
        """Test numerical accuracy of temperature conversion with known values."""
        # Test with known Planck constants for accuracy validation
        mock_ds = MagicMock()
        mock_ds.attrs = {
            "planck_fk1": 202263.0,
            "planck_fk2": 3698.0,
            "planck_bc1": 0.5,
            "planck_bc2": 0.9991,
        }

        # Test with values that should produce specific temperatures
        # Using Planck function: T = FK2 / ln((FK1/L) + 1) - BC1) / BC2
        test_radiances = np.array([50.0, 100.0, 150.0, 200.0, 250.0])

        result = _convert_radiance_to_temperature(test_radiances, mock_ds, DEFAULT_MIN_TEMP_K, DEFAULT_MAX_TEMP_K)

        # Handle masked arrays
        result_data = np.ma.filled(result, fill_value=0.0) if hasattr(result, "filled") else result

        # Verify results are in valid range
        assert np.all(result_data >= 0.0), "Temperature values should be >= 0"
        assert np.all(result_data <= 1.0), "Temperature values should be <= 1"

        # Verify monotonic relationship (higher radiance -> higher temp -> lower normalized value)
        # Since we invert the normalized temperature (1 - normalized),
        # higher radiance should result in lower final values
        for i in range(len(result_data) - 1):
            if not np.isnan(result_data[i]) and not np.isnan(result_data[i + 1]):
                # Allow for some numerical precision issues
                assert result_data[i] >= result_data[i + 1] - 1e-6, (
                    f"Temperature conversion should maintain monotonic relationship: {result_data[i]} >= {result_data[i + 1]}"
                )

    def test_data_corruption_handling(self, memory_test_generator: Any) -> None:
        """Test handling of various types of data corruption."""
        corruption_types = ["infinite_values", "nan_blocks", "extreme_values", "zero_division", "mixed_corruption"]

        for corruption_type in corruption_types:
            dataset = memory_test_generator.create_corrupted_dataset(corruption_type)

            # Test temperature conversion with corrupted data
            radiance_data = dataset[RADIANCE_VAR].values
            result = _convert_radiance_to_temperature(radiance_data, dataset, DEFAULT_MIN_TEMP_K, DEFAULT_MAX_TEMP_K)

            # Handle masked arrays
            result_data = np.ma.filled(result, fill_value=0.0) if hasattr(result, "filled") else result

            # Verify function doesn't crash and produces valid output shape
            assert result_data.shape == radiance_data.shape, f"Output shape mismatch for {corruption_type}"

            # Check that finite values are in valid range
            finite_values = result_data[np.isfinite(result_data)]
            if len(finite_values) > 0:
                assert np.all(finite_values >= 0.0), f"Finite values should be >= 0 for {corruption_type}"
                assert np.all(finite_values <= 1.0), f"Finite values should be <= 1 for {corruption_type}"

    def test_extreme_memory_usage(self, memory_test_generator: Any) -> None:
        """Test behavior with large datasets."""
        # Test with moderately large dataset to avoid segfaults
        large_dataset = memory_test_generator.create_large_dataset(300, 300, realistic_radiance=True)

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            nc_path = temp_path / "large_test.nc"
            png_path = temp_path / "large_test.png"

            try:
                # Create the NetCDF file
                large_dataset.to_netcdf(nc_path)

                # Monitor memory before rendering
                gc.collect()

                # Test rendering with large file
                with patch("goesvfi.integrity_check.render.netcdf._create_figure") as mock_create:
                    start_time = time.time()
                    result_path = render_png(nc_path, png_path)
                    end_time = time.time()

                    # Verify rendering completed
                    assert result_path == png_path
                    mock_create.assert_called_once()

                    # Performance check - should complete within reasonable time
                    assert end_time - start_time < 30.0, "Large file rendering took too long"

                # Force garbage collection
                gc.collect()

            finally:
                # Cleanup
                if nc_path.exists():
                    nc_path.unlink()

    def test_invalid_netcdf_structure(self) -> None:
        """Test handling of NetCDF files with invalid or unexpected structure."""
        # Test with dataset missing critical variables
        invalid_datasets = []

        # Dataset with wrong variable names
        invalid_datasets.append(
            xr.Dataset({
                "invalid_radiance": (["y", "x"], np.random.random((50, 50))),
                "invalid_band": 13,
            })
        )

        # Dataset with wrong dimensions
        invalid_datasets.append(
            xr.Dataset({
                RADIANCE_VAR: (["time", "level"], np.random.random((10, 10))),
                BAND_ID_VAR: TARGET_BAND_ID,
            })
        )

        # Dataset with wrong coordinate names (skip scalar test to avoid segfaults)
        invalid_datasets.append(
            xr.Dataset({
                RADIANCE_VAR: (["wrong_y", "wrong_x"], np.random.random((10, 10))),
                BAND_ID_VAR: TARGET_BAND_ID,
            })
        )

        for i, invalid_ds in enumerate(invalid_datasets):
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                nc_path = temp_path / f"invalid_{i}.nc"
                png_path = temp_path / f"invalid_{i}.png"

                try:
                    invalid_ds.to_netcdf(nc_path)

                    # Test should raise appropriate error
                    with pytest.raises((ValueError, KeyError, AttributeError)):
                        render_png(nc_path, png_path)

                finally:
                    if nc_path.exists():
                        nc_path.unlink()

    def test_colormap_edge_cases(self) -> None:
        """Test colormap handling with various edge cases."""
        # Test with invalid colormap names
        invalid_colormaps = ["nonexistent_colormap", "", "invalid123", "null"]

        for colormap_name in invalid_colormaps:
            # Should fallback to viridis for invalid colormaps
            cmap = _get_colormap(colormap_name)
            assert cmap is not None
            assert callable(cmap)  # Should be callable like a colormap

        # Test with valid but unusual colormap names
        valid_colormaps = ["viridis", "plasma", "gray", "jet", "coolwarm"]

        for colormap_name in valid_colormaps:
            cmap = _get_colormap(colormap_name)
            assert cmap is not None
            assert callable(cmap)

            # Test colormap can generate colors
            test_values = np.array([0.0, 0.5, 1.0])
            colors = cmap(test_values)
            assert colors.shape == (3, 4)  # 3 values, RGBA
            assert np.all(colors >= 0.0)
            assert np.all(colors <= 1.0)

    def test_band_validation_edge_cases(self) -> None:
        """Test band validation with various edge cases and data types."""
        # Test with different band ID data types
        test_cases = [
            (np.array([13]), "array with correct band"),
            (np.array([1, 13, 14]), "array containing correct band"),
            (np.int32(13), "int32 scalar"),
            (np.int64(13), "int64 scalar"),
            (b"13", "bytes"),
            ("13", "string"),
        ]

        for band_value, _description in test_cases:
            mock_ds = MagicMock()
            mock_band_var = MagicMock()
            mock_band_var.values = band_value
            mock_ds.variables = {BAND_ID_VAR: mock_band_var}
            mock_ds.__getitem__ = MagicMock(return_value=mock_band_var)

            try:
                _validate_band_id(mock_ds)
                # Should succeed for valid cases
            except ValueError:
                # Might fail for some edge cases, which is acceptable
                pass

        # Test with clearly wrong band IDs
        wrong_bands = [1, 2, 14, 16, "wrong", b"wrong"]

        for wrong_band in wrong_bands:
            mock_ds = MagicMock()
            mock_band_var = MagicMock()
            mock_band_var.values = wrong_band
            mock_ds.variables = {BAND_ID_VAR: mock_band_var}
            mock_ds.__getitem__ = MagicMock(return_value=mock_band_var)

            with pytest.raises(ValueError):
                _validate_band_id(mock_ds)

    def test_metadata_extraction_robustness(self) -> None:
        """Test metadata extraction with various data structure edge cases."""
        # Test with challenging but safe attribute structures
        complex_dataset = xr.Dataset(
            {
                RADIANCE_VAR: (["y", "x"], np.random.random((10, 10))),
                BAND_ID_VAR: TARGET_BAND_ID,
            },
            attrs={
                "platform_ID": "GOES-18",  # Normal string (avoid nested structures that cause segfaults)
                "instrument_type": "ABI",  # Normal string
                "date_created": "2024-01-15T12:00:00Z",  # Normal string
                "custom_metadata": "simple_value",  # Simple string instead of nested
            },
        )

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            nc_path = temp_path / "complex_metadata.nc"

            try:
                complex_dataset.to_netcdf(nc_path)

                # Should handle complex metadata gracefully
                metadata = extract_metadata(nc_path)

                # Verify basic structure
                assert isinstance(metadata, dict)
                assert "satellite" in metadata
                assert "instrument" in metadata
                assert "timestamp" in metadata

            finally:
                if nc_path.exists():
                    nc_path.unlink()

    def test_concurrent_processing_stress(self, memory_test_generator: Any) -> None:
        """Test system behavior under concurrent processing stress."""
        import concurrent.futures
        import threading

        results: list[dict[str, Any]] = []
        errors: list[tuple[int, str]] = []
        lock = threading.Lock()

        def process_dataset(dataset_id: int) -> None:
            """Process a dataset concurrently."""
            try:
                dataset = memory_test_generator.create_large_dataset(100, 100, realistic_radiance=True)

                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_path = Path(temp_dir)
                    nc_path = temp_path / f"concurrent_{dataset_id}.nc"
                    png_path = temp_path / f"concurrent_{dataset_id}.png"

                    dataset.to_netcdf(nc_path)

                    # Mock figure creation to avoid actual file I/O
                    with patch("goesvfi.integrity_check.render.netcdf._create_figure"):
                        start_time = time.time()
                        result_path = render_png(nc_path, png_path)
                        end_time = time.time()

                        with lock:
                            results.append({
                                "dataset_id": dataset_id,
                                "processing_time": end_time - start_time,
                                "result_path": result_path,
                            })

            except Exception as e:
                with lock:
                    errors.append((dataset_id, str(e)))

        # Process multiple datasets concurrently
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(process_dataset, i) for i in range(8)]
            concurrent.futures.wait(futures)

        # Verify results
        assert len(errors) == 0, f"Concurrent processing errors: {errors}"
        assert len(results) == 8, f"Expected 8 results, got {len(results)}"

        # Check performance consistency
        processing_times = [r["processing_time"] for r in results]
        avg_time = sum(processing_times) / len(processing_times)
        assert avg_time < 5.0, "Average processing time too high under concurrent load"

    def test_planck_function_numerical_stability(self) -> None:
        """Test numerical stability of Planck function with edge cases."""
        mock_ds = MagicMock()
        mock_ds.attrs = {
            "planck_fk1": 202263.0,
            "planck_fk2": 3698.0,
            "planck_bc1": 0.5,
            "planck_bc2": 0.9991,
        }

        # Test with values that might cause numerical issues
        edge_cases = [
            np.array([1e-10, 1e-5, 1e-1]),  # Very small values
            np.array([1e5, 1e8, 1e10]),  # Very large values
            np.array([202263.0]),  # Exactly FK1 (division by zero in log)
            np.array([202262.9, 202263.1]),  # Very close to FK1
        ]

        for radiance_values in edge_cases:
            result = _convert_radiance_to_temperature(radiance_values, mock_ds, DEFAULT_MIN_TEMP_K, DEFAULT_MAX_TEMP_K)

            # Handle masked arrays
            result_data = np.ma.filled(result, fill_value=0.0) if hasattr(result, "filled") else result

            # Verify no invalid values produced
            assert not np.any(np.isnan(result_data)), "NaN values produced by Planck function"
            assert not np.any(np.isinf(result_data)), "Infinite values produced by Planck function"
            assert result_data.shape == radiance_values.shape, "Output shape mismatch"

    def test_temperature_range_validation(self) -> None:
        """Test temperature range validation and clamping."""
        mock_ds = MagicMock()
        mock_ds.attrs = {
            "planck_fk1": 202263.0,
            "planck_fk2": 3698.0,
            "planck_bc1": 0.5,
            "planck_bc2": 0.9991,
        }

        # Test with various temperature ranges
        test_ranges = [
            (100.0, 400.0),  # Wide range
            (280.0, 290.0),  # Narrow range
            (0.1, 1000.0),  # Very wide range
            (250.0, 250.1),  # Extremely narrow range
        ]

        radiance = np.array([50.0, 100.0, 150.0, 200.0])

        for min_temp, max_temp in test_ranges:
            result = _convert_radiance_to_temperature(radiance, mock_ds, min_temp, max_temp)

            # Handle masked arrays
            result_data = np.ma.filled(result, fill_value=0.0) if hasattr(result, "filled") else result

            # Verify normalization is correct
            assert np.all(result_data >= 0.0), f"Values below 0 for range {min_temp}-{max_temp}"
            assert np.all(result_data <= 1.0), f"Values above 1 for range {min_temp}-{max_temp}"

            # For narrow ranges, all values should be similar
            if max_temp - min_temp < 1.0:
                value_range = np.max(result_data) - np.min(result_data)
                assert value_range < 0.1, "Too much variation for narrow temperature range"

    def test_file_permission_handling(self) -> None:
        """Test handling of file permission issues."""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # Create a valid NetCDF file
            dataset = xr.Dataset({
                RADIANCE_VAR: (["y", "x"], np.random.random((10, 10))),
                BAND_ID_VAR: TARGET_BAND_ID,
            })

            nc_path = temp_path / "permission_test.nc"
            dataset.to_netcdf(nc_path)

            # Test with read-only output directory
            readonly_dir = temp_path / "readonly"
            readonly_dir.mkdir()

            try:
                # Make directory read-only
                readonly_dir.chmod(0o444)

                output_path = readonly_dir / "output.png"

                # Should handle permission error gracefully
                with patch("goesvfi.integrity_check.render.netcdf._create_figure") as mock_create:
                    mock_create.side_effect = PermissionError("Permission denied")

                    with pytest.raises(PermissionError):
                        render_png(nc_path, output_path)

            finally:
                # Restore permissions for cleanup
                readonly_dir.chmod(0o755)

    def test_memory_leak_detection(self, memory_test_generator: Any) -> None:
        """Test for potential memory leaks during repeated operations."""
        import psutil

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        # Perform many operations that could potentially leak memory
        for i in range(5):  # Reduce iterations to prevent memory issues
            dataset = memory_test_generator.create_large_dataset(50, 50, realistic_radiance=True)

            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                nc_path = temp_path / f"memory_test_{i}.nc"
                png_path = temp_path / f"memory_test_{i}.png"

                dataset.to_netcdf(nc_path)

                with patch("goesvfi.integrity_check.render.netcdf._create_figure"):
                    render_png(nc_path, png_path)

                # Extract metadata multiple times
                for _ in range(3):
                    extract_metadata(nc_path)

            # Force garbage collection
            gc.collect()

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        # Allow for some memory increase but detect significant leaks
        # 100MB increase might indicate a memory leak
        assert memory_increase < 100 * 1024 * 1024, (
            f"Potential memory leak detected: {memory_increase / 1024 / 1024:.1f} MB increase"
        )
